{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with Haystack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait, RAG again?\n",
    "In the notebook 02, we implemented a RAG pipeline from scratch, using only the Qdrant and the OpenAI SDK.\n",
    "Now, we want to build something similar using Haystack. Once agiain, we expect to get a more readable and maintanable code, at the expense of taking on an extra dependency, and one that will forever be entangled in our application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup: packages and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWRZeaVJS3LA",
    "outputId": "24292119-8a0f-49de-f137-a18eb0dcdb47"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from haystack import Pipeline, Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ...\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a pipeline to create embeddings\n",
    "\n",
    "The first step is to embed documents. We'll use an the `InMemoryDocumentStore`, an in-memory structure that is a much simplified version of a vector database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        content=\"Poor Things is a 2023 film directed by Yorgos Lanthimos and written by Tony McNamara, \"\n",
    "        \"based on the 1992 novel by Alasdair Gray.\"\n",
    "    ),\n",
    "    Document(\n",
    "        content=\"Oppenheimer is a 2023 epic biographical thriller film[a] written, directed,\"\n",
    "        \" and co-produced by Christopher Nolan.[8] It follows the life of J. Robert \"\n",
    "        \"Oppenheimer, the American theoretical physicist who helped develop the \"\n",
    "        \"first nuclear weapons during World War II\"\n",
    "    ),\n",
    "    Document(\n",
    "        content=\"Dune: Part Two is a 2024 American epic science fiction film directed and produced by Denis \"\n",
    "        \"Villeneuve, who co-wrote the screenplay with Jon Spaihts. The sequel to Dune (2021), it \"\n",
    "        \"is the second of a two-part adaptation of the 1965 novel Dune by Frank Herbert. \"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWeZFFXAVzup"
   },
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "indexing_pipeline = Pipeline()\n",
    "# Add the embedded and the document writer components to the pipeline\n",
    "indexing_pipeline.connect(\"doc_embedder.documents\", \"doc_writer.documents\")\n",
    "indexing_pipeline.run({\"doc_embedder\": {\"documents\": documents}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the documents are there..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.filter_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline\n",
    "\n",
    "Great, now we can buid the proper RAG pipeline using our documents.\n",
    "As in notebook 02, we need a prompt template. However, this time we will use a real templating engine, [Jinja](https://jinja.palletsprojects.com/en/3.1.x/). \n",
    "\n",
    "We will implement our RAG as a Pipiline. Pipelines are the key abstraction of Haystack (and Langchain, and Llamaindex). \n",
    "\n",
    "The pipelines in Haystack 2.0 are directed multigraphs of different Haystack components and integrations. They give the freedom to connect these components in various ways. This means that the pipeline doesn't need to be a continuous stream of information. With the flexibility of Haystack pipelines, you can have simultaneous flows, standalone components, loops, and other types of connections.\n",
    "\n",
    "Learn more at https://docs.haystack.deepset.ai/docs/pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the questions based on the given context.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "Question: {{ question }}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipe = Pipeline()\n",
    "\n",
    "# Here you need an embedded, a retriever, a prompt builder and finally a generator.\n",
    "\n",
    "rag_pipe.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag_pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipe.connect(\"prompt_builder\", \"llm\")\n",
    "\n",
    "rag_pipe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "query = \"What film talks about the atomic bomb?\"\n",
    "response = rag_pipe.run(\n",
    "    {\"embedder\": {\"text\": query}, \"prompt_builder\": {\"question\": query}}\n",
    ")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
