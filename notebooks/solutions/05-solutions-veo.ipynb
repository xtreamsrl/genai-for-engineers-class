{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if not importlib.util.find_spec(\"utils\"):\n",
    "    !pip install -qqq git+https://github.com/xtreamsrl/genai-for-engineers-class\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdL4uvQQs76x"
   },
   "source": [
    "# Veo 3 Video Generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDjAqcgigwdX"
   },
   "source": [
    "Veo 3.1 by Google is an advanced video generation model available on Vertex AI. It enables developers to create high-quality, realistic videos from text and image prompts, supporting a wide range of visual styles and including features like dialogue and audio generation. Veo 3.1 excels in producing videos with detailed visuals and lifelike physics, making it suitable for cinematic and creative applications.\n",
    "\n",
    "Main features:\n",
    "- Generates videos from text and image prompts\n",
    "- Supports various visual styles and cinematic effects\n",
    "- Includes audio and dialogue generation\n",
    "- Offers prompt enhancement for improved video quality\n",
    "- Allows customization of camera angles, movements, and lens effects\n",
    "- Supports different aspect ratios, resolutions, and durations\n",
    "\n",
    "In this notebook, we use Google Gen AI SDK and APIs to interact with Veo 3.1, demonstrating its capabilities through practical examples and exploring its features programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVrasKoriKZn"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMQf_BkyiMgF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from IPython.display import Markdown, Video, display\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qD_bwA9hiMzL"
   },
   "source": [
    "### Define a helper function to display media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUrEwbvFiPhJ"
   },
   "outputs": [],
   "source": [
    "def create_video(video: bytes, video_tmp_path: Path = None) -> Video:\n",
    "    temp_video_path = video_tmp_path or Path(\"temp_video.mp4\")\n",
    "    temp_video_path.write_bytes(video)\n",
    "    return Video(temp_video_path, embed=True, width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jaSOOadiUj6"
   },
   "source": [
    "### Load the video generation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APRfTklCiYR2"
   },
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "\n",
    "video_model = (\n",
    "    \"veo-3.1-fast-generate-preview\"  # Use \"veo-3.1-generate-preview\" for higher quality\n",
    ")\n",
    "image_model = \"gemini-2.5-flash-image\"\n",
    "gemini_model = \"gemini-2.5-pro\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_R1_Y76i4QB"
   },
   "source": [
    "## Generate videos\n",
    "Now, you'll generate videos from text and/or image prompts. You can get started with your own prompts or complete the section below to optimize your prompts with some established best practices.\n",
    "\n",
    "Video generation with Veo 3.1 is significantly slower than generating text or images because it requires more computational resources and time to produce high-quality, realistic videos. As a result, the Google APIs do not return the final video immediately. Instead, you must poll the API at intervals to check if the video generation operation is complete. This polling mechanism ensures you can retrieve the result as soon as it is ready, without blocking your code execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_video_completion(operation: genai.types.GenerateVideosOperation) -> Video:\n",
    "    waited_time = 0\n",
    "    wait_interval = 10\n",
    "    while not operation.done:\n",
    "        time.sleep(wait_interval)\n",
    "        waited_time += wait_interval\n",
    "        print(f\"Waited {waited_time} seconds. Checking operation...\")\n",
    "        operation = client.operations.get(operation)\n",
    "        print(operation)\n",
    "\n",
    "    video_url = f\"{operation.response.generated_videos[0].video.uri}&key={os.getenv('GOOGLE_API_KEY')}\"\n",
    "    video_response = requests.get(video_url, stream=True)\n",
    "    return create_video(video_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A realistic video of a cat shooting with a baseball bat in a stadium, cinematic lighting, high detail\"\n",
    "\n",
    "response = client.models.generate_videos(\n",
    "    model=video_model,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "wait_for_video_completion(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9ERu5b3EEdp"
   },
   "source": [
    "## Optimize your prompt: Text-to-video\n",
    "\n",
    "By considering the following options in your prompt, you can use Veo to create higher quality videos that more closely resemble your desired outcome. Learn more about advanced [prompting techniques for Veo 3](https://medium.com/google-cloud/veo-3-a-detailed-prompting-guide-867985b46018). To get started specify the following, or leave them as `None` if they don't align with your specific goals.\n",
    "- **Subject:** The \"who\" or \"what\" of your video\n",
    "- **Action:** Describe movements, interactions, etc.\n",
    "- **Scene:** The \"where\" and \"when\" of your video\n",
    "- **Camera angles:** The shot's viewpoint\n",
    "- **Camera movements:** For a more cinematic/dynamic experience\n",
    "- **Lens effects:** How the camera \"sees\" the world\n",
    "- **Style:** The video's artistic filter\n",
    "- **Temporal elements:** To imply changes in time\n",
    "- **Audio:** Various sound effects or dialogue that guides the visuals through sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yx7DKfqri3Vf"
   },
   "outputs": [],
   "source": [
    "subject = \"a detective\"  # @param {type: 'string'}\n",
    "action = \"interrogating a rubber duck\"  # @param {type: 'string'}\n",
    "scene = \"in a dark interview room\"  # @param {type: 'string'}\n",
    "\n",
    "camera_angle = \"Over-the-Shoulder Shot\"  # @param [\"None\", \"Eye-Level Shot\", \"Low-Angle Shot\", \"High-Angle Shot\", \"Bird's-Eye View\", \"Top-Down Shot\", \"Worm's-Eye View\", \"Dutch Angle\", \"Canted Angle\", \"Close-Up\", \"Extreme Close-Up\", \"Medium Shot\", \"Full Shot\", \"Long Shot\", \"Wide Shot\", \"Establishing Shot\", \"Over-the-Shoulder Shot\", \"Point-of-View (POV) Shot\"]\n",
    "camera_movement = \"Zoom (In)\"  # @param [\"None\", \"Static Shot (or fixed)\", \"Pan (left)\", \"Pan (right)\", \"Tilt (up)\", \"Tilt (down)\", \"Dolly (In)\", \"Dolly (Out)\", \"Zoom (In)\", \"Zoom (Out)\", \"Truck (Left)\", \"Truck (Right)\", \"Pedestal (Up)\", \"Pedestal (Down)\", \"Crane Shot\", \"Aerial Shot\", \"Drone Shot\", \"Handheld\", \"Shaky Cam\", \"Whip Pan\", \"Arc Shot\"]\n",
    "lens_effects = \"None\"  # @param [\"None\", \"Wide-Angle Lens (e.g., 24mm)\", \"Telephoto Lens (e.g., 85mm)\", \"Shallow Depth of Field\", \"Bokeh\", \"Deep Depth of Field\", \"Lens Flare\", \"Rack Focus\", \"Fisheye Lens Effect\", \"Vertigo Effect (Dolly Zoom)\"]\n",
    "style = \"Cinematic\"  # @param [\"None\", \"Photorealistic\", \"Cinematic\", \"Vintage\", \"Japanese anime style\", \"Claymation style\", \"Stop-motion animation\", \"In the style of Van Gogh\", \"Surrealist painting\", \"Monochromatic black and white\", \"Vibrant and saturated\", \"Film noir style\", \"High-key lighting\", \"Low-key lighting\", \"Golden hour glow\", \"Volumetric lighting\", \"Backlighting to create a silhouette\"]\n",
    "temporal_elements = \"None\"  # @param [\"None\", \"Slow-motion\", \"Fast-paced action\", \"Time-lapse\", \"Hyperlapse\", \"Pulsating light\", \"Rhythmic movement\"]\n",
    "\n",
    "sound_effects = \"Ticking clock\"  # @param [\"None\", \"Sound of a phone ringing\", \"Water splashing\", \"Soft house sounds\", \"Ticking clock\", \"City traffic and sirens\", \"Waves crashing\", \"Quiet office hum\"]\n",
    "dialogue = \"Where were you last night?\"  # @param {type: 'string'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMFj078dLG0D"
   },
   "source": [
    "Now, you'll use Gemini to take all of these keywords and combine them into a detailed Veo prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "id": "f3jvksummytE",
    "outputId": "129f247c-d3d2-4bee-9b72-7a0bf2d05667"
   },
   "outputs": [],
   "source": [
    "maybe_keywords = [\n",
    "    subject,\n",
    "    action,\n",
    "    scene,\n",
    "    camera_angle,\n",
    "    camera_movement,\n",
    "    lens_effects,\n",
    "    style,\n",
    "    temporal_elements,\n",
    "    sound_effects,\n",
    "]\n",
    "keywords = [k for k in maybe_keywords if k != \"None\"]\n",
    "\n",
    "if dialogue != \"\":\n",
    "    keywords.append(dialogue)\n",
    "\n",
    "gemini_prompt = f\"\"\"\n",
    "You are an expert video prompt engineer for Google's Veo model.\n",
    "Your task is to construct the most effective prompt using the following keywords.\n",
    "Every single keyword MUST be included.\n",
    "Synthesize them into a single, cohesive, and cinematic instruction.\n",
    "Output ONLY the final prompt string, without any introduction or explanation.\n",
    "\n",
    "Keywords: {\",\".join(keywords)}\n",
    "\"\"\"\n",
    "response = client.models.generate_content(\n",
    "    model=gemini_model,\n",
    "    contents=gemini_prompt,\n",
    ")\n",
    "\n",
    "# Set Gemini's response in a prompt variable\n",
    "prompt = response.text\n",
    "display(Markdown(response.text))\n",
    "\n",
    "response = client.models.generate_videos(\n",
    "    model=video_model,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "wait_for_video_completion(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate videos from an image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-NdoBONKpJD"
   },
   "source": [
    "#### Download the starting image\n",
    "\n",
    "You can also generate a video by starting with an input image.\n",
    "\n",
    "In this example, you'll first generate an image using Gemini 2.5 Flash Image, and then use that image as the starting point for a video generation with Veo 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1NvfHEHrx2m"
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "prompt = \"Panning wide shot of a calico kitten sleeping in the sunshine\"\n",
    "\n",
    "# Step 1: Generate an image with Nano Banana.\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-image\",\n",
    "    contents=prompt,\n",
    ")\n",
    "\n",
    "# Step 2: Generate a video with Veo 3.1 using the image from Step 1 as input.\n",
    "for part in response.candidates[0].content.parts:\n",
    "    if part.text is not None:\n",
    "        print(part.text)\n",
    "    elif part.inline_data is not None:\n",
    "        image_bytes = part.inline_data.data\n",
    "        image = Image.open(BytesIO(image_bytes))\n",
    "        image.save(\"generated_image.png\")\n",
    "\n",
    "        response = client.models.generate_videos(\n",
    "            model=video_model,\n",
    "            source=genai.types.GenerateVideosSource(\n",
    "                prompt=prompt,\n",
    "                image=genai.types.Image(image_bytes=image_bytes, mime_type=\"image/png\"),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        wait_for_video_completion(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "veo3_video_generation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
