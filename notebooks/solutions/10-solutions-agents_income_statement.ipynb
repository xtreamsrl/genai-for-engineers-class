{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents to parse and comment an income statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we will try and use agents to download, parse, and comment on an income statement.\n",
    "\n",
    "The document is real, and it is publicly available on the internet at the time of writing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup: packages and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec(\"class_utils\"):\n",
    "    !pip install -qqq git+https://github.com/xtreamsrl/genai-for-engineers-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWRZeaVJS3LA",
    "outputId": "24292119-8a0f-49de-f137-a18eb0dcdb47"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import autogen\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating agents\n",
    "\n",
    "For this purpose, we will use the latest model, GPT-4o.\n",
    "\n",
    "Less advanced models are less effective in writing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [{\"model\": \"gpt-4.1\"}],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Proxy\n",
    "UserProxyAgent is a special type of agent that can be used to proxy user input to another agent or group of agents. It supports the following human input modes:\n",
    "- ALWAYS: Always ask user for input.\n",
    "- NEVER: Never ask user for input. In this mode, the agent will use the default response (if any) to respond to the message. Or using underlying LLM model to generate response if provided.\n",
    "- AUTO: Only ask user for input when conversation is terminated by the other agent(s). Otherwise, use the default response (if any) to respond to the message. Or using underlying LLM model to generate response if provided.\n",
    "\n",
    "We will execute the code natively without docker. This is a security flaw, and in real life it should be avoided, as the execution of arbitrary code can expose sensitive data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"income_statement_analysis\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Engineer, Software Engineer Critic, and Financial Analysists\n",
    "\n",
    "Next we define our agents according to their role.\n",
    "\n",
    "In essence, an agent is definied by its system prompt. Then, it will take part in the conversation as if it was a human being.\n",
    "\n",
    "We will define:\n",
    "- a software engineer, taked with developing the python code to perform a task,\n",
    "- a software engineer critic, that will criticise the code written by the coder, and suggest improvements, and\n",
    "- a financial analyst, that should read and understand the income statement and create a report about it.\n",
    "\n",
    "Once the chat is triggered, the agents should collaborate autonomously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_eng = autogen.AssistantAgent(\n",
    "    name=\"Software_Engineer\",\n",
    "    description=\"Software Engineer writing code\",\n",
    "    system_message=\"\"\"\n",
    "    You are helpful Senior Software Engineer, highly skilled in writing python code.\n",
    "    When there are tasks that require writing code, such as extracting data from documents, \n",
    "    you must provide the snippets.\n",
    "    In case updates are required, you must provide them.\n",
    "    In case bugs are found, you must fix them quickly.\n",
    "    When you extract text from a document, always print the extracted text.\n",
    "    When you are asked for some data, always write some code to print it.\n",
    "    Always save your code to a file named \"script.py\".\n",
    "    Always parse full documents, not just parts of them.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_eng_critic = autogen.AssistantAgent(\n",
    "    name=\"Software_Engineer_Critic\",\n",
    "    description=\"Software Engineer evaluating code\",\n",
    "    system_message=\"\"\"\n",
    "    You are a Senior Software Engineer, highly skilled in evaluating python code.\n",
    "    When some code is proposed by other agents, you must evaluate it and provide feedback.\n",
    "    If you find any syntax error or logic errors, you must point them out, providing effective actions to fix them.\n",
    "    If you find any issue harming the readability or efficiency of the code, you must provide feedback.\n",
    "    Never write code, just suggest improvements and then ask the Software Engineer to improve the code.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_analyst = autogen.AssistantAgent(\n",
    "    name=\"Financial_Analyst\",\n",
    "    description=\"Financial Analyst evaluating income statements\",\n",
    "    system_message=\"\"\"\n",
    "    You are a highly skilled Financial Analyst, specialized in evaluating income statements.\n",
    "    You have perfect knowledge of the structure of an income statement and can evaluate it effectively.\n",
    "    You know how to write a brief, effective, yet precise report on the evaluation of an income statement.\n",
    "    Only speak after the data has been extracted, otherwise you must ask the Software Engineer to extract the data.\n",
    "    Remember, you must ask specifically to the Software Engineer.\n",
    "    Once you have all the data you need, you must write a brief report on the evaluation of the income statement \n",
    "    and must must ask the Software Engineer to write and save a markdown file \"report.md\" with your report.\n",
    "    If some data extracted from the income statement is not clear, you must ask for clarification.\n",
    "    Never suggest code, just comment on the extracted data.\n",
    "    Once all the tasks have been completed, you must terminate the conversation with the special \n",
    "    command \"TERMINATE CONVERSATION\". Use this command only when you have completed all the tasks.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=lambda msg: \"terminate conversation\"\n",
    "    in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_chat = autogen.GroupChat(\n",
    "    agents=[user_proxy, sw_eng, sw_eng_critic, financial_analyst],\n",
    "    messages=[],\n",
    "    max_round=30,\n",
    "    send_introductions=True,\n",
    ")\n",
    "\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=group_chat,\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the chat\n",
    "Let's trigger the grup chat and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://www.cisiaonline.it/sites/default/files/AmmTrasparente/2025/Schema-bilancio-consuntivo-CISIA-2024-e-nota-di-accompagnamento.pdf\"\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=f\"At this link is an income statement: {link}. \"\n",
    "    \"Please evaluate it, considering it is written in Italian.\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
